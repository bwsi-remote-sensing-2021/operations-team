{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59403b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    from torchvision import transforms, utils\n",
    "except:\n",
    "    !conda install --yes torchvision --no-channel-priority\n",
    "    from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "try:\n",
    "    from torchvision import transforms, utils\n",
    "except:\n",
    "    !pip install torchvision\n",
    "    from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# You want to change these to be your own filenames\n",
    "csv_file = 'flood_sample_metadata.csv'\n",
    "label_csv = 'flood_sample_label.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d24e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b5927",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the tsv file with the labels\n",
    "ladi_responses = pd.read_csv(\"http://ladi.s3-us-west-2.amazonaws.com/Labels/ladi_aggregated_responses_url.tsv\",delimiter='\\t',header='infer')\n",
    "ladi_responses.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6548d036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    plt.imshow(image)\n",
    "    plt.pause(0.01)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i, sample in enumerate(ladi_responses):\n",
    "    print(sample)\n",
    "    print(sample['Answer'])\n",
    "    print(i, \n",
    "          sample['Answer'], \n",
    "          sample['url'])\n",
    "#           sample['uuid'], \n",
    "#           sample['timestamp'], \n",
    "#           sample['gps_lat'], \n",
    "#           sample['gps_lon'], \n",
    "#           sample['gps_alt'])\n",
    "\n",
    "    plt.tight_layout()\n",
    "#     plt.title('Sample #{}'.format(i))\n",
    "\n",
    "    if i == 500:\n",
    "        show_image(sample['image'])\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip off bracket and comma from the Answer catagory\n",
    "ladi_responses[\"Answer\"] = ladi_responses[\"Answer\"].str.strip('[|]')\n",
    "# split list of responses into multiple rows\n",
    "ladi_responses[\"Answer\"] = ladi_responses[\"Answer\"].str.split(\",\",expand = True)\n",
    "# remove the single quote character from either end of string\n",
    "ladi_responses[\"Answer\"] = ladi_responses[\"Answer\"].str.strip('\\'')\n",
    "# add a column to help with aggregation when pivoting\n",
    "ladi_responses[\"response_count\"] = 1\n",
    "# Create a matrix with the number of workers who answered given label for given image\n",
    "# using pivot table; filling in nan values with 0\n",
    "label_matrix = ladi_responses.pivot_table(values='response_count', \n",
    "                                          index='url', \n",
    "                                          columns='Answer', \n",
    "                                          aggfunc='sum',\n",
    "                                          fill_value=0)\n",
    "label_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5217b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose rows where more workers voted for damage=flood/water than none\n",
    "flood_examples = label_matrix[label_matrix['damage:flood/water']>label_matrix['damage:none']]\n",
    "flood_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159a2ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select negative examples as those where more workers annotated damage=none than flood/water\n",
    "non_flood_examples = label_matrix[label_matrix['damage:flood/water']<label_matrix['damage:none']]\n",
    "non_flood_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec2bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ladi_images_metadata.csv\n",
    "metadata = pd.read_csv('http://ladi.s3-us-west-2.amazonaws.com/Labels/ladi_images_metadata.csv')\n",
    "\n",
    "# sampling\n",
    "sample_size=1000\n",
    "flood_sample = flood_examples.sample(sample_size)\n",
    "non_flood_sample = non_flood_examples.sample(sample_size)\n",
    "\n",
    "# creating a df with True/False labels for flooding\n",
    "training_flood = pd.DataFrame(index=flood_sample.index, data={'label':True}).reset_index()\n",
    "training_non_flood = pd.DataFrame(index=non_flood_sample.index, data={'label':False}).reset_index()\n",
    "label_df = pd.concat([training_flood, training_non_flood], ignore_index=True)\n",
    "\n",
    "label_df.to_csv('flood_sample_label.csv')\n",
    "\n",
    "# create list of urls to download\n",
    "label_df['url'].to_csv('urls_to_download.csv', index=False, header=False)\n",
    "\n",
    "# Get flood and non-flood metadata\n",
    "flood_metadata = metadata[metadata['url'].isin(flood_sample.index)]\n",
    "not_flood_metadata = metadata[metadata['url'].isin(non_flood_sample.index)]\n",
    "training_metadata = pd.concat([flood_metadata, not_flood_metadata], ignore_index=True)\n",
    "\n",
    "training_metadata.to_csv('flood_sample_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee90963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenient function for showing the images\n",
    "def show_image(image):\n",
    "    plt.imshow(image)\n",
    "    # pause a bit so that plots are updated\n",
    "    plt.pause(0.01)\n",
    "\n",
    "def convert_url_to_local_path(url):\n",
    "    '''\n",
    "    gets the location of the downloaded image\n",
    "    '''\n",
    "    return 'training_images/'+url.split('/')[-1]\n",
    "\n",
    "class FloodSampleDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, label_csv, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with metadata.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.flood_sample_metadata = pd.read_csv(csv_file)\n",
    "        # get the path in the shared directory\n",
    "        self.flood_sample_metadata['local_path'] = self.flood_sample_metadata['url'].apply(convert_url_to_local_path)\n",
    "        self.flood_sample_label = pd.read_csv(label_csv)\n",
    "        self.flood_sample_data = pd.merge(self.flood_sample_metadata, \n",
    "                                        self.flood_sample_label,\n",
    "                                       on=\"url\")\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.flood_sample_metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        ## Load images from local directory. There is no need to redownload images to local machine. ##\n",
    "        local_path = self.flood_sample_metadata.iloc[idx]['local_path']\n",
    "        url = self.flood_sample_metadata.iloc[idx]['url']\n",
    "        try:\n",
    "            image = Image.fromarray(io.imread(local_path))\n",
    "            img_name = local_path\n",
    "        except:\n",
    "            image = Image.fromarray(io.imread(url))\n",
    "            img_name = url\n",
    "        uuid = self.flood_sample_data.iloc[idx, 1]\n",
    "        timestamp = self.flood_sample_data.iloc[idx, 2]\n",
    "        gps_lat = self.flood_sample_data.iloc[idx, 3]\n",
    "        gps_lon = self.flood_sample_data.iloc[idx, 4]\n",
    "        gps_alt = self.flood_sample_data.iloc[idx, 5]\n",
    "        file_size = self.flood_sample_data.iloc[idx, 6]\n",
    "        width = self.flood_sample_data.iloc[idx, 7]\n",
    "        height = self.flood_sample_data.iloc[idx, 8]\n",
    "        label = self.flood_sample_data.iloc[idx, -1]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        sample = {'image': image, \n",
    "                  'image_name': img_name, \n",
    "                  'damage:flood/water': label, \n",
    "                  'uuid': uuid, \n",
    "                  'timestamp': timestamp, \n",
    "                  'gps_lat': gps_lat, \n",
    "                  'gps_lon': gps_lon, \n",
    "                  'gps_alt': gps_alt, \n",
    "                  'orig_file_size': file_size, \n",
    "                  'orig_width': width, \n",
    "                  'orig_height': height}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e91f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_sample_dataset = FloodSampleDataset(csv_file = csv_file, label_csv = label_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf032fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = transforms.Resize(768)\n",
    "crop = transforms.RandomCrop(512)\n",
    "rotate = transforms.RandomRotation(20)\n",
    "flip_demo = transforms.RandomHorizontalFlip(1) # flip with 100% chance just to demo\n",
    "flip = transforms.RandomHorizontalFlip(p=0.5)\n",
    "composed = transforms.Compose([scale,\n",
    "                               crop,\n",
    "                               rotate,\n",
    "                               flip_demo])\n",
    "\n",
    "# Apply each of the above transforms on sample.\n",
    "fig = plt.figure()\n",
    "sample = flood_sample_dataset[198]\n",
    "for i, tsfrm in enumerate([scale, crop, rotate, flip_demo, composed]):\n",
    "    transformed_image = tsfrm(sample['image'])\n",
    "\n",
    "    ax = plt.subplot(2, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title(type(tsfrm).__name__)\n",
    "    show_image(transformed_image)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220685b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = FloodSampleDataset(csv_file = csv_file, \n",
    "                                       label_csv = label_csv, \n",
    "                                       transform = transforms.Compose([scale, \n",
    "                                                                       crop, \n",
    "                                                                       rotate, \n",
    "                                                                       flip, \n",
    "                                                                       transforms.ToTensor()]\n",
    "                                                                     )\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d8780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "test_split_ratio = .2\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "# num_workers = 1\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(transformed_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(test_split_ratio * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                                           sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                                                sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25da9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "try:\n",
    "    from cnn_finetune import make_model\n",
    "except:\n",
    "    !pip install cnn-finetune\n",
    "    from cnn_finetune import make_model\n",
    "\n",
    "net = make_model('resnet50', num_classes=2, pretrained=True).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f1d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c8b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_checkpoint_path(epoch):\n",
    "    return f'epoch_checkpoints/flood_checkpoint_epoch{epoch}.pth'\n",
    "\n",
    "torch.backends.cudnn.benchmark = True # flag for some GPU optimizations\n",
    "starting_epoch = 1\n",
    "additional_epochs = 30\n",
    "if starting_epoch > 1:\n",
    "    net.load_state_dict(torch.load(get_checkpoint_path(starting_epoch)))\n",
    "for epoch in range(starting_epoch, starting_epoch+additional_epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = data['image'].cuda()\n",
    "        labels = data['damage:flood/water'].cuda()\n",
    "        # casting int to long for loss calculation#\n",
    "        labels = labels.long()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 10 == 0:    # print every 10 mini-batches\n",
    "            print(f'[epoch {epoch}, batch {i +1} ] average loss: {running_loss/10}')\n",
    "            running_loss = 0.0\n",
    "    # save the model\n",
    "    PATH = get_checkpoint_path(epoch)\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "single_iter = dataiter.next()\n",
    "images = single_iter['image']\n",
    "labels = single_iter['damage:flood/water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22941f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "outputs = net(images.cuda())\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % predicted[j].cpu()\n",
    "                              for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e55df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images = data['image'].cuda()\n",
    "        labels = data['damage:flood/water'].cuda()\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69546a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_labels = []\n",
    "predicted_labels = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images = data['image'].cuda()\n",
    "        labels = data['damage:flood/water'].cuda()\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        truth_labels.append(labels.cpu())\n",
    "        predicted_labels.append(predicted.cpu())\n",
    "truth_labels = np.concatenate([x.numpy() for x in truth_labels])\n",
    "predicted_labels = np.concatenate([x.numpy() for x in predicted_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fafd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(truth_labels, predicted_labels)\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix, ['flood','no flood'])\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
