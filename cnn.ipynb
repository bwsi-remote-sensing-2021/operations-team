{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906bf290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    from torchvision import transforms, utils\n",
    "except:\n",
    "    !conda install --yes torchvision --no-channel-priority\n",
    "    from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "try:\n",
    "    from torchvision import transforms, utils\n",
    "except:\n",
    "    !pip install torchvision\n",
    "    from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# You want to change these to be your own filenames\n",
    "csv_file = 'flood_sample_metadata.csv'\n",
    "label_csv = 'flood_sample_label.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee2b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenient function for showing the images\n",
    "def show_image(image):\n",
    "    plt.imshow(image)\n",
    "    # pause a bit so that plots are updated\n",
    "    plt.pause(0.01)\n",
    "\n",
    "def convert_url_to_local_path(url):\n",
    "    '''\n",
    "    gets the location of the downloaded image\n",
    "    '''\n",
    "    return 'training_images/'+url.split('/')[-1]\n",
    "\n",
    "class FloodSampleDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, label_csv, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with metadata.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.flood_sample_metadata = pd.read_csv(csv_file)\n",
    "        # get the path in the shared directory\n",
    "        self.flood_sample_metadata['local_path'] = self.flood_sample_metadata['url'].apply(convert_url_to_local_path)\n",
    "        self.flood_sample_label = pd.read_csv(label_csv)\n",
    "        self.flood_sample_data = pd.merge(self.flood_sample_metadata, \n",
    "                                        self.flood_sample_label,\n",
    "                                       on=\"url\")\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.flood_sample_metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        ## Load images from local directory. There is no need to redownload images to local machine. ##\n",
    "        local_path = self.flood_sample_metadata.iloc[idx]['local_path']\n",
    "        url = self.flood_sample_metadata.iloc[idx]['url']\n",
    "        try:\n",
    "            image = Image.fromarray(io.imread(local_path))\n",
    "            img_name = local_path\n",
    "        except:\n",
    "            image = Image.fromarray(io.imread(url))\n",
    "            img_name = url\n",
    "        uuid = self.flood_sample_data.iloc[idx, 1]\n",
    "        timestamp = self.flood_sample_data.iloc[idx, 2]\n",
    "        gps_lat = self.flood_sample_data.iloc[idx, 3]\n",
    "        gps_lon = self.flood_sample_data.iloc[idx, 4]\n",
    "        gps_alt = self.flood_sample_data.iloc[idx, 5]\n",
    "        file_size = self.flood_sample_data.iloc[idx, 6]\n",
    "        width = self.flood_sample_data.iloc[idx, 7]\n",
    "        height = self.flood_sample_data.iloc[idx, 8]\n",
    "        label = self.flood_sample_data.iloc[idx, -1]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        sample = {'image': image, \n",
    "                  'image_name': img_name, \n",
    "                  'damage:flood/water': label, \n",
    "                  'uuid': uuid, \n",
    "                  'timestamp': timestamp, \n",
    "                  'gps_lat': gps_lat, \n",
    "                  'gps_lon': gps_lon, \n",
    "                  'gps_alt': gps_alt, \n",
    "                  'orig_file_size': file_size, \n",
    "                  'orig_width': width, \n",
    "                  'orig_height': height}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d9693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_sample_dataset = FloodSampleDataset(csv_file = csv_file, label_csv = label_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82bb666",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = transforms.Resize(768)\n",
    "crop = transforms.RandomCrop(512)\n",
    "rotate = transforms.RandomRotation(20)\n",
    "flip_demo = transforms.RandomHorizontalFlip(1) # flip with 100% chance just to demo\n",
    "flip = transforms.RandomHorizontalFlip(p=0.5)\n",
    "composed = transforms.Compose([scale,\n",
    "                               crop,\n",
    "                               rotate,\n",
    "                               flip_demo])\n",
    "\n",
    "# Apply each of the above transforms on sample.\n",
    "fig = plt.figure()\n",
    "sample = flood_sample_dataset[198]\n",
    "for i, tsfrm in enumerate([scale, crop, rotate, flip_demo, composed]):\n",
    "    transformed_image = tsfrm(sample['image'])\n",
    "\n",
    "    ax = plt.subplot(2, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title(type(tsfrm).__name__)\n",
    "    show_image(transformed_image)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1903cf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = FloodSampleDataset(csv_file = csv_file, \n",
    "                                       label_csv = label_csv, \n",
    "                                       transform = transforms.Compose([scale, \n",
    "                                                                       crop, \n",
    "                                                                       rotate, \n",
    "                                                                       flip, \n",
    "                                                                       transforms.ToTensor()]\n",
    "                                                                     )\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253e0ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "test_split_ratio = .2\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "# num_workers = 1\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(transformed_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(test_split_ratio * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                                           sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                                                sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff9d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "try:\n",
    "    from cnn_finetune import make_model\n",
    "except:\n",
    "    !pip install cnn-finetune\n",
    "    from cnn_finetune import make_model\n",
    "\n",
    "net = make_model('resnet18', num_classes=2, pretrained=True).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39404239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf363b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_checkpoint_path(epoch):\n",
    "    return f'epoch_checkpoints/flood_checkpoint_epoch{epoch}.pth'\n",
    "\n",
    "torch.backends.cudnn.benchmark = True # flag for some GPU optimizations\n",
    "starting_epoch = 1\n",
    "additional_epochs = 30\n",
    "if starting_epoch > 1:\n",
    "    net.load_state_dict(torch.load(get_checkpoint_path(starting_epoch)))\n",
    "for epoch in range(starting_epoch, starting_epoch+additional_epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = data['image'].cuda()\n",
    "        labels = data['damage:flood/water'].cuda()\n",
    "        # casting int to long for loss calculation#\n",
    "        labels = labels.long()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 10 == 0:    # print every 10 mini-batches\n",
    "            print(f'[epoch {epoch}, batch {i +1} ] average loss: {running_loss/10}')\n",
    "            running_loss = 0.0\n",
    "    # save the model\n",
    "    PATH = get_checkpoint_path(epoch)\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c09551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "single_iter = dataiter.next()\n",
    "images = single_iter['image']\n",
    "labels = single_iter['damage:flood/water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5392474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "outputs = net(images.cuda())\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % predicted[j].cpu()\n",
    "                              for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab6b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images = data['image'].cuda()\n",
    "        labels = data['damage:flood/water'].cuda()\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a89356",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_labels = []\n",
    "predicted_labels = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images = data['image'].cuda()\n",
    "        labels = data['damage:flood/water'].cuda()\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        truth_labels.append(labels.cpu())\n",
    "        predicted_labels.append(predicted.cpu())\n",
    "truth_labels = np.concatenate([x.numpy() for x in truth_labels])\n",
    "predicted_labels = np.concatenate([x.numpy() for x in predicted_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69667df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(truth_labels, predicted_labels)\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix, ['flood','no flood'])\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
